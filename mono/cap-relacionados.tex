%% ------------------------------------------------------------------------- %%
\chapter{Related Works}

As GPUs became famous by its massively parallel capabilities and 
applications were developed to explore its potential, there is no 
surprise that researchers would use GPUs to accelerate
Boundary Elements Method implementations. 

\cite{torky:2017} presented an implementation for generating 
both $H$ and $G$ matrices of equation 1.2 with GPU acceleration 
using two CUDA kernels: One for computing the $G$ matrix and one 
for computing $H$ matrix. They also manage to keep the $H$ matrix 
in GPU memory to avoid host to device memory transfer to solve 
the linear system on the GPU, managing a 
108$\times$ speedup when building both $H$ and $G$ using single 
precision on a NVIDIA GeForce 770GTX when compared with an 
Intel Core i7-3770. For the linear system solving, the CPU required 
2.5h to complete, whereas with the GPU it would take 4s. This implies 
in a 2250 times speedup. As for precision, there is no further discussion 
rather than the usage of 10 points for the Gaussian Quadrature and that both 
CPU and GPU processed data in exactly the same manner and with reliable 
accuracy. 
